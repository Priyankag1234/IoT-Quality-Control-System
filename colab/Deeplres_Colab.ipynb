{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab45beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "\n",
    "!pip install -q kagglehub scikit-learn pillow matplotlib seaborn pandas tqdm tensorflow\n",
    "\n",
    "\n",
    "# Download dataset via kagglehub and auto-detect bottle folder\n",
    "import kagglehub, os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "base_path = Path(kagglehub.dataset_download(\"ipythonx/mvtec-ad\"))\n",
    "print(\"Base path:\", base_path)\n",
    "\n",
    "# Search for 'bottle' subfolder anywhere under base_path\n",
    "bottle_path = None\n",
    "for root, dirs, files in os.walk(base_path):\n",
    "    if \"bottle\" in dirs:\n",
    "        bottle_path = Path(root) / \"bottle\"\n",
    "        break\n",
    "if bottle_path is None:\n",
    "#Show top-level structure for debugging\n",
    "   print(\"Could not find 'bottle' inside the dataset. Top-level contents:\")\n",
    "   for p in base_path.iterdir():\n",
    "       print(\" \", p.name)\n",
    "   raise FileNotFoundError(\"Bottle folder not found inside KaggleHub dataset. If using other packaging, upload or set path manually.\")else:\n",
    "else:\n",
    "    data_dir = bottle_path\n",
    "    print(\"Using bottle dataset at:\", data_dir)  \n",
    "# Prepare dataset structure: dataset/train/{Normal,Defective}, dataset/test/{Normal,Defective}\n",
    "from pathlib import Path\n",
    "import os, shutil\n",
    "\n",
    "train_dir = Path(\"dataset/train\")\n",
    "test_dir = Path(\"dataset/test\")\n",
    "\n",
    "def prepare_dataset_from_mvtec(data_dir):\n",
    "    # clear existing\n",
    "        if Path(\"dataset\").exists():\n",
    "           shutil.rmtree(\"dataset\")\n",
    "        (train_dir / \"Normal\").mkdir(parents=True, exist_ok=True)\n",
    "        (train_dir / \"Defective\").mkdir(parents=True, exist_ok=True)\n",
    "        (test_dir / \"Normal\").mkdir(parents=True, exist_ok=True)\n",
    "        (test_dir / \"Defective\").mkdir(parents=True, exist_ok=True)\n",
    "        for p in (data_dir / \"train\" / \"good\").glob(\"*.png\"):\n",
    "            shutil.copy(p, train_dir / \"Normal\")\n",
    "        for p in (data_dir / \"test\" / \"good\").glob(\"*.png\"):\n",
    "            shutil.copy(p, test_dir / \"Normal\")\n",
    "        for defect_type in (data_dir / \"train\").iterdir():\n",
    "            if defect_type.is_dir() and defect_type.name != \"good\":\n",
    "                for p in defect_type.glob(\"*.png\"):\n",
    "                    shutil.copy(p, train_dir / \"Defective\")\n",
    "                for defect_type in (data_dir / \"test\").iterdir():\n",
    "                    if defect_type.is_dir() and defect_type.name != \"good\":\n",
    "                        for p in defect_type.glob(\"*.png\"):\n",
    "                            shutil.copy(p, test_dir / \"Defective\")\n",
    "\n",
    "prepare_dataset_from_mvtec(data_dir)\n",
    "print(\"Dataset prepared. Counts:\")\n",
    "for root, dirs, files in os.walk(\"dataset\"):\n",
    "    print(root, \"->\", len(files))\n",
    "# CONFIG\n",
    "IMG_SIZE = 224            # recommended size for EfficientNet / ImageNet backbones\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 25\n",
    "AUTOTUNE = True\n",
    "\n",
    "# Ensure the dataset directory exists\n",
    "import os\n",
    "from pathlib import Path\n",
    "train_dir = Path(\"dataset/train\")\n",
    "test_dir = Path(\"dataset/test\")\n",
    "\n",
    "if not train_dir.exists():\n",
    "    print(\"Dataset directory not found. Please run the cell to prepare the dataset first.\")\n",
    "else:\n",
    "    # Data generators with augmentation (train) and deterministic (val/test)\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "    import numpy as np\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.12,\n",
    "        height_shift_range=0.12,\n",
    "        shear_range=0.08,\n",
    "        zoom_range=0.12,\n",
    "        brightness_range=(0.75,1.25),\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='reflect',\n",
    "        validation_split=0.15\n",
    "     ) \n",
    "     test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "     # NOTE: EfficientNet expects 3-channel RGB. MVTec images are grayscale;\n",
    "     # we'll convert grayscale to RGB by duplicating channels via color_mode='rgb'\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "         \"dataset/train\",\n",
    "         target_size=(IMG_SIZE, IMG_SIZE),\n",
    "         color_mode='rgb',   # convert grayscale to RGB automatically\n",
    "         batch_size=BATCH_SIZE,\n",
    "         class_mode='binary',\n",
    "         subset='training',\n",
    "         shuffle=True\n",
    "      )\n",
    "      val_generator = train_datagen.flow_from_directory(\n",
    "        \"dataset/train\",\n",
    "         target_size=(IMG_SIZE, IMG_SIZE),\n",
    "         color_mode='rgb',\n",
    "         batch_size=BATCH_SIZE,\n",
    "         class_mode='binary',\n",
    "         subset='validation',\n",
    "         shuffle=True\n",
    "     )\n",
    "     test_generator = test_datagen.flow_from_directory(\n",
    "        \"dataset/test\",\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        color_mode='rgb',\n",
    "        batch_size=1,\n",
    "        class_mode='binary',\n",
    "        shuffle=False\n",
    "     ) \n",
    "\n",
    "    print(\"Train samples:\", train_generator.samples)\n",
    "    print(\"Val samples:\", val_generator.samples)\n",
    "    print(\"Test samples:\", test_generator.samples)\n",
    "# Transfer learning using EfficientNetB0 (lightweight & accurate)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "\n",
    "def build_model_finetune(input_shape=(IMG_SIZE, IMG_SIZE, 3), base_trainable=False):\n",
    "    base = tf.keras.applications.EfficientNetB0(\n",
    "        include_top=False, weights='imagenet', input_shape=input_shape, pooling='avg'\n",
    "    )\n",
    "    base.trainable = base_trainable  # start with frozen base, then optionally unfreeze\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = tf.keras.applications.efficientnet.preprocess_input(inputs)  # same preprocessing\n",
    "    x = base(x, training=False)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=1e-4)\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "    return model, base\n",
    "\n",
    "model, base_model = build_model_finetune()\n",
    "model.summary()\n",
    "# Compute class weights (helps if classes are imbalanced)\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "y_train_classes = train_generator.classes\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_classes), y=y_train_classes)\n",
    "class_weights = {i: w for i, w in enumerate(class_weights)}\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "# Callbacks\n",
    "callbacks_list = [\n",
    "    callbacks.ModelCheckpoint(\"best_mvtec_model.h5\", monitor='val_accuracy', save_best_only=True, mode='max', verbose=1),\n",
    "    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
    "    callbacks.EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True, verbose=1)\n",
    " ]\n",
    "history1 = model.fit(\n",
    "      train_generator,\n",
    "      validation_data=val_generator,\n",
    "      epochs=EPOCHS,\n",
    "      class_weight=class_weights,\n",
    "      callbacks=callbacks_list,\n",
    "      verbose=2\n",
    "\n",
    ")\n",
    "# Unfreeze last blocks of base model and fine-tune with lower lr\n",
    "base_model.trainable = True\n",
    "\n",
    "# Freeze first N layers (so only later layers train)\n",
    "fine_tune_at = int(len(base_model.layers) * 0.6)\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-5),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    " )\n",
    "history2 = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10,               # a few more epochs for fine-tuning\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=2\n",
    " )\n",
    "\n",
    "# Load best model (if checkpoint saved)\n",
    "from tensorflow.keras.models import load_model\n",
    "best = load_model(\"best_mvtec_model.h5\", compile=False)\n",
    "best.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "# Evaluate\n",
    "loss, acc, auc = best.evaluate(test_generator, verbose=0)\n",
    "print(f\"Test accuracy: {acc*100:.2f}%, Test AUC: {auc:.4f}\")\n",
    "\n",
    "# Predictions & reports\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "test_steps = test_generator.samples\n",
    "test_generator.reset()\n",
    "preds_prob = best.predict(test_generator, steps=test_steps, verbose=0).ravel()\n",
    "preds = (preds_prob > 0.5).astype(int)\n",
    "y_true = test_generator.classes\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_true, preds, labels=[0, 1])\n",
    "print(cm)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, preds, target_names=[\"Normal\",\"Defective\"], labels=[0, 1]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
